{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>...</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>CreditScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>8557.39</td>\n",
       "      <td>797.115833</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1767.29</td>\n",
       "      <td>25.400823</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>13.168404</td>\n",
       "      <td>91.952879</td>\n",
       "      <td>3.0</td>\n",
       "      <td>264.590301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>19718.92</td>\n",
       "      <td>1676.243333</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2057.56</td>\n",
       "      <td>28.642449</td>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>64.066440</td>\n",
       "      <td>107.668408</td>\n",
       "      <td>3.0</td>\n",
       "      <td>285.889485</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>32045.78</td>\n",
       "      <td>2677.481667</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1333.18</td>\n",
       "      <td>30.053861</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>169.770374</td>\n",
       "      <td>62.681178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>285.296615</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>62976.28</td>\n",
       "      <td>5321.023333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>68.66</td>\n",
       "      <td>40.661773</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.780837</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.321496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>57818.72</td>\n",
       "      <td>4864.226667</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2348.77</td>\n",
       "      <td>37.882655</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>73.709570</td>\n",
       "      <td>395.136222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>307.576874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85265</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>76230.76</td>\n",
       "      <td>6159.563333</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1961.73</td>\n",
       "      <td>34.222384</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>15026.000000</td>\n",
       "      <td>176.547124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>539.747953</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85266</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>110607.09</td>\n",
       "      <td>8997.257500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1174.05</td>\n",
       "      <td>24.781202</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>154.824136</td>\n",
       "      <td>232.178801</td>\n",
       "      <td>5.0</td>\n",
       "      <td>752.722813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85267</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>96275.84</td>\n",
       "      <td>8101.986667</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999.36</td>\n",
       "      <td>28.339005</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>64.961337</td>\n",
       "      <td>129.831967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>855.405363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85268</th>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>69388.26</td>\n",
       "      <td>5543.355000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>819.98</td>\n",
       "      <td>40.497795</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>184.212607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>640.122893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85269</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>26738.26</td>\n",
       "      <td>2058.188333</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>828.93</td>\n",
       "      <td>29.985336</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>86.263356</td>\n",
       "      <td>16.606857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>342.948620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85270 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_1  col_2      col_3        col_4  col_5  col_6  col_7  col_8  \\\n",
       "0         22     14    8557.39   797.115833      8      6     22      2   \n",
       "1         37      1   19718.92  1676.243333     10      9     19      6   \n",
       "2         33     13   32045.78  2677.481667      6      9     30      7   \n",
       "3         42      4   62976.28  5321.023333      0      3     12      0   \n",
       "4         39      2   57818.72  4864.226667      7      7     21      2   \n",
       "...      ...    ...        ...          ...    ...    ...    ...    ...   \n",
       "85265     23      6   76230.76  6159.563333      6     10     31      3   \n",
       "85266     46      0  110607.09  8997.257500      4      4      2      3   \n",
       "85267     50      8   96275.84  8101.986667      6      6     19      1   \n",
       "85268     55      9   69388.26  5543.355000      2      4      6      0   \n",
       "85269     40      8   26738.26  2058.188333      7      6     20      6   \n",
       "\n",
       "       col_9  col_10  ...  col_13   col_14     col_15  col_16  col_17  \\\n",
       "0         37    15.0  ...       0  1767.29  25.400823     143       2   \n",
       "1         27    11.0  ...       2  2057.56  28.642449     197       2   \n",
       "2         10    10.0  ...       2  1333.18  30.053861      76       2   \n",
       "3          9     0.0  ...       1    68.66  40.661773     191       1   \n",
       "4         56    16.0  ...       0  2348.77  37.882655     174       2   \n",
       "...      ...     ...  ...     ...      ...        ...     ...     ...   \n",
       "85265     35    15.0  ...       2  1961.73  34.222384     242       2   \n",
       "85266      2     9.0  ...       1  1174.05  24.781202     265       1   \n",
       "85267      7    18.0  ...       2   999.36  28.339005     321       0   \n",
       "85268      8     1.0  ...       1   819.98  40.497795     266       1   \n",
       "85269     10    13.0  ...       2   828.93  29.985336      74       2   \n",
       "\n",
       "             col_18      col_19  col_20      col_21  CreditScore  \n",
       "0         13.168404   91.952879     3.0  264.590301            2  \n",
       "1         64.066440  107.668408     3.0  285.889485            2  \n",
       "2        169.770374   62.681178     4.0  285.296615            2  \n",
       "3          0.000000   70.780837     4.0  711.321496            1  \n",
       "4         73.709570  395.136222     3.0  307.576874            2  \n",
       "...             ...         ...     ...         ...          ...  \n",
       "85265  15026.000000  176.547124     1.0  539.747953            2  \n",
       "85266    154.824136  232.178801     5.0  752.722813            0  \n",
       "85267     64.961337  129.831967     NaN  855.405363            0  \n",
       "85268      0.000000  184.212607     1.0  640.122893            2  \n",
       "85269     86.263356   16.606857     5.0  342.948620            0  \n",
       "\n",
       "[85270 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check some information about the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show The Number Of Observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col_2, col_13, col_17, col_20 are categorical variables for df\n",
    "# col_2: 0, 1, 2, ..., 15\n",
    "# col_13: 0, 1, 2, 3\n",
    "# col_17: 0, 1, 2\n",
    "# col_20: 0, 1, 2, 3, 4, 5\n",
    "\n",
    "#print('df shape:', df.shape)\n",
    "#print('df_test shape:', df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_1              0\n",
       "col_2              0\n",
       "col_3              0\n",
       "col_4          12817\n",
       "col_5              0\n",
       "col_6              0\n",
       "col_7              0\n",
       "col_8              0\n",
       "col_9              0\n",
       "col_10          6004\n",
       "col_11          1799\n",
       "col_12          1661\n",
       "col_13             0\n",
       "col_14             0\n",
       "col_15             0\n",
       "col_16             0\n",
       "col_17             0\n",
       "col_18             0\n",
       "col_19          3836\n",
       "col_20          6502\n",
       "col_21          1024\n",
       "CreditScore        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "#df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the mean and median to deal with the missing value \n",
    "# We should clean col_4, 10, 11, 12, 19, 20, 21\n",
    "# Since col_20 is categorical value, we use median\n",
    "# Others are numeric features, we use mean\n",
    "# If testing is not well, we can try put most frequent to fill in missing value\n",
    "\n",
    "col_median_fill = ['col_4', 'col_10', 'col_11', 'col_12', 'col_19', 'col_20', 'col_21']\n",
    "\n",
    "for col in col_median_fill:\n",
    "    df[col].fillna(df[col].median(), inplace = True)\n",
    "    df_test[col].fillna(df_test[col].median(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_1          0\n",
       "col_2          0\n",
       "col_3          0\n",
       "col_4          0\n",
       "col_5          0\n",
       "col_6          0\n",
       "col_7          0\n",
       "col_8          0\n",
       "col_9          0\n",
       "col_10         0\n",
       "col_11         0\n",
       "col_12         0\n",
       "col_13         0\n",
       "col_14         0\n",
       "col_15         0\n",
       "col_16         0\n",
       "col_17         0\n",
       "col_18         0\n",
       "col_19         0\n",
       "col_20         0\n",
       "col_21         0\n",
       "CreditScore    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encoding on Categorical Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df_preprocessed: 47\n",
      "len of df_test_preprocessed: 46\n"
     ]
    }
   ],
   "source": [
    "# Do one-hot encoding on the categorical data col_2, col_13, col_17, col_20\n",
    "col_to_encoded = ['col_2','col_13', 'col_17', 'col_20']\n",
    "df_preprocessed = pd.get_dummies(df, columns = col_to_encoded)\n",
    "df_test_preprocessed = pd.get_dummies(df_test, columns = col_to_encoded)\n",
    "\n",
    "print('len of df_preprocessed:', len(df_preprocessed.columns.tolist()))\n",
    "print('len of df_test_preprocessed:', len(df_test_preprocessed.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data And Deal with data imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 68216\n",
      "testing data set: 17054\n"
     ]
    }
   ],
   "source": [
    "X = df_preprocessed.drop('CreditScore', axis = 1)\n",
    "y = df_preprocessed['CreditScore']\n",
    "\n",
    "# Get training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('training data size:', len(X_train))\n",
    "print('testing data set:', len(X_test))\n",
    "\n",
    "# Oversampling on the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    37355\n",
      "0    37355\n",
      "1    37355\n",
      "Name: CreditScore, dtype: int64\n",
      "y_test: 0    9383\n",
      "2    4939\n",
      "1    2732\n",
      "Name: CreditScore, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled.value_counts())\n",
    "print('y_test:', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train_resampled)\n",
    "X_test_std = sc.transform(X_test)\n",
    "df_test_std = sc.transform(df_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest(RF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC result: [0 0 0 ... 0 1 0]\n",
      "Misclassified samples: 4181\n",
      "Accuracy: 0.7548\n",
      "F1-score for class 0:0.7859\n",
      "F1-score for class 1:0.6586\n",
      "F1-score for class 2:0.7572\n",
      "Average F1 score across all classes: 0.7339\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "# Train\n",
    "rfc.fit(X_train_std, y_train_resampled)\n",
    "\n",
    "# Predict\n",
    "y_pred_rfc = rfc.predict(X_test_std)\n",
    "\n",
    "#classification_report(y_test, y_pred_rfc)\n",
    "# Evaluation\n",
    "print('RFC result:', y_pred_rfc)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_rfc).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_rfc)) \n",
    "\n",
    "# Show the F1-score\n",
    "f1_scores = {}\n",
    "for class_label in set(y_pred_rfc):\n",
    "    y_true_f1 = [1 if label == class_label else 0 for label in y_test]\n",
    "    y_pred_f1 = [1 if label == class_label else 0 for label in y_pred_rfc]\n",
    "\n",
    "    f1_scores[class_label] = f1_score(y_true_f1, y_pred_f1)\n",
    "\n",
    "for class_label, f in f1_scores.items():\n",
    "    print(\"F1-score for class {}:{:.4f}\".format(class_label, f))\n",
    "\n",
    "avg_f1_score = sum(f1_scores.values()) / len(f1_scores)\n",
    "print(\"Average F1 score across all classes: {:.4f}\".format(avg_f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick Something Important And Repredict again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC result: [0 0 1 ... 0 1 0]\n",
      "Misclassified samples: 3744\n",
      "Accuracy: 0.7805\n",
      "F1-score for class 0:0.7984\n",
      "F1-score for class 1:0.7096\n",
      "F1-score for class 2:0.7912\n",
      "Average F1 score across all classes: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# Use selector to select feature\n",
    "selector = SelectFromModel(rfc, prefit=True, threshold = '0.9*mean')\n",
    "X_train_selected = selector.transform(X_train_std)\n",
    "X_test_selected = selector.transform(X_test_std)\n",
    "df_test_selected = selector.transform(df_test_std)\n",
    "# Create a Random Forest Classifier\n",
    "rfc_filtered = RandomForestClassifier(n_estimators=150)\n",
    "# Train\n",
    "rfc_filtered.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Predict\n",
    "y_filtered_pred_rfc = rfc_filtered.predict(X_test_selected)\n",
    "\n",
    "# Evaluation\n",
    "print('RFC result:', y_filtered_pred_rfc)\n",
    "print('Misclassified samples: %d' %(y_test != y_filtered_pred_rfc).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_filtered_pred_rfc)) \n",
    "\n",
    "# Show the F1-score\n",
    "f1_scores = {}\n",
    "for class_label in set(y_filtered_pred_rfc):\n",
    "    y_true_f1 = [1 if label == class_label else 0 for label in y_test]\n",
    "    y_pred_f1 = [1 if label == class_label else 0 for label in y_filtered_pred_rfc]\n",
    "\n",
    "    f1_scores[class_label] = f1_score(y_true_f1, y_pred_f1)\n",
    "\n",
    "for class_label, f in f1_scores.items():\n",
    "    print(\"F1-score for class {}:{:.4f}\".format(class_label, f))\n",
    "\n",
    "avg_f1_score = sum(f1_scores.values()) / len(f1_scores)\n",
    "print(\"Average F1 score across all classes: {:.4f}\".format(avg_f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4232\n",
      "[LightGBM] [Info] Number of data points in the train set: 112065, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "GBM result: [0 0 0 ... 0 1 0]\n",
      "Misclassified samples: 4737\n",
      "Accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,  # 可調整\n",
    "    'verbose': -1  # 這會減少大量的輸出信息\n",
    "}\n",
    "\n",
    "GBM_train_data = lgb.Dataset(X_train_std, label = y_train_resampled)\n",
    "GBM_test_data = lgb.Dataset(X_test_std, label=y_test, reference = GBM_train_data)\n",
    "\n",
    "# Create LightGBM classifier\n",
    "LGBM = LGBMClassifier(objective = 'multiclass',\n",
    "                      num_class = 3,\n",
    "                      learning_rate = 0.1,\n",
    "                      n_estimators = 100,\n",
    "                      num_leaves = 31,\n",
    "                      subsample = 0.8,\n",
    "                      colsample_bytree = 0.8,\n",
    "                      reg_lambda = 1,\n",
    "                      reg_alpha = 0.1,\n",
    "                      random_state = 42)\n",
    "\n",
    "LGBM.fit(X_train_std,\n",
    "         y_train_resampled, \n",
    "         eval_set=[(X_test_std, y_test)],\n",
    "         eval_metric='multi_logloss')\n",
    "\n",
    "y_pred_LGBM = LGBM.predict(X_test_std)\n",
    "\n",
    "# Evaluation\n",
    "print('GBM result:', y_pred_LGBM)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_LGBM).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_LGBM)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB result: [0 0 0 ... 0 1 0]\n",
      "Misclassified samples: 4051\n",
      "Accuracy: 0.7625\n",
      "F1-score for class 0:0.7906\n",
      "F1-score for class 1:0.6824\n",
      "F1-score for class 2:0.7544\n",
      "Average F1 score across all classes: 0.7425\n"
     ]
    }
   ],
   "source": [
    "# max_depth set 20 is better\n",
    "XGB = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                        num_class = 3, \n",
    "                        learning_rate = 0.15, \n",
    "                        n_estimators = 300,\n",
    "                        max_depth = 6,\n",
    "                        subsample = 0.8,\n",
    "                        colsample_bytree = 0.8,\n",
    "                        reg_lambda = 1,\n",
    "                        reg_alpha = 0.1,\n",
    "                        use_label_encoder = False,\n",
    "                        eval_metric = 'mlogloss')\n",
    "\n",
    "XGB.fit(X_train_std, y_train_resampled)\n",
    "\n",
    "y_pred_xgb = XGB.predict(X_test_std)\n",
    "\n",
    "# Evaluation\n",
    "print('XGB result:', y_pred_xgb)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_xgb).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_xgb)) \n",
    "\n",
    "# Show the F1-score\n",
    "f1_scores = {}\n",
    "for class_label in set(y_pred_xgb):\n",
    "    y_true_f1 = [1 if label == class_label else 0 for label in y_test]\n",
    "    y_pred_f1 = [1 if label == class_label else 0 for label in y_pred_xgb]\n",
    "\n",
    "    f1_scores[class_label] = f1_score(y_true_f1, y_pred_f1)\n",
    "\n",
    "for class_label, f in f1_scores.items():\n",
    "    print(\"F1-score for class {}:{:.4f}\".format(class_label, f))\n",
    "\n",
    "avg_f1_score = sum(f1_scores.values()) / len(f1_scores)\n",
    "print(\"Average F1 score across all classes: {:.4f}\".format(avg_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict test.csv using XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_y_pred = XGB.predict(df_test_std)\n",
    "fin_y_pred\n",
    "fin_df = pd.DataFrame({'label': fin_y_pred})\n",
    "fin_df.to_csv('xgb_output_0416.csv', index = True, index_label = 'Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick Some Important Feature And Repredict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_selected result: [0 0 2 ... 0 1 0]\n",
      "Misclassified samples: 4304\n",
      "Accuracy: 0.7476\n"
     ]
    }
   ],
   "source": [
    "XGB_feature_importance = XGB.feature_importances_\n",
    "col_name = X.columns.tolist()\n",
    "\n",
    "threshold = 0.006\n",
    "XGB_feature_importance_col = [i for i, v in enumerate(XGB_feature_importance) if v >= threshold]\n",
    "X_train_std_selected = X_train_std[:, XGB_feature_importance_col]\n",
    "X_test_std_selected = X_test_std[:, XGB_feature_importance_col]\n",
    "\n",
    "XGB_selected = xgb.XGBClassifier(objective = 'multi:softmax', \n",
    "                                 num_class = 3, \n",
    "                                 learning_rate = 0.1, \n",
    "                                 n_estimators = 100,\n",
    "                                 max_depth = 20,\n",
    "                                 subsample = 0.8,\n",
    "                                 colsample_bytree = 0.8,\n",
    "                                 reg_lambda = 1,\n",
    "                                 reg_alpha = 0.1,\n",
    "                                 use_label_encoder = False,\n",
    "                                 eval_metric = 'mlogloss')\n",
    "\n",
    "XGB_selected.fit(X_train_std_selected, y_train_resampled)\n",
    "y_pred_xgb_sel = XGB_selected.predict(X_test_std_selected)\n",
    "\n",
    "# Evaluation\n",
    "print('XGB_selected result:', y_pred_xgb_sel)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_xgb_sel).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_xgb_sel)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RGF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jack/opt/anaconda3/lib/python3.8/site-packages/rgf/utils.py:224: UserWarning: Cannot find FastRGF executable files. FastRGF estimators will be unavailable for usage.\n",
      "  warnings.warn(\"Cannot find FastRGF executable files. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"predict\": \n",
      "   model_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/6a3e0b2e-fb7a-44bd-9478-7bd9532a0e2a1.model-10\n",
      "   test_x_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/6a3e0b2e-fb7a-44bd-9478-7bd9532a0e2a1.test.data.x\n",
      "   prediction_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/6a3e0b2e-fb7a-44bd-9478-7bd9532a0e2a1.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Tue Apr 16 20:42:34 2024: Reading test data ... \n",
      "Tue Apr 16 20:42:34 2024: Predicting ... \n",
      "elapsed: 0.070895\n",
      "/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/6a3e0b2e-fb7a-44bd-9478-7bd9532a0e2a1.predictions.txt: /var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/6a3e0b2e-fb7a-44bd-9478-7bd9532a0e2a1.model-10,#leaf=1000,#tree=79\n",
      "Tue Apr 16 20:42:34 2024: Done ... \n",
      "\n",
      "\"predict\": \n",
      "   model_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/665bceba-78e2-46c5-9cec-653d08426c8f2.model-10\n",
      "   test_x_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/665bceba-78e2-46c5-9cec-653d08426c8f2.test.data.x\n",
      "   prediction_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/665bceba-78e2-46c5-9cec-653d08426c8f2.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Tue Apr 16 20:42:35 2024: Reading test data ... \n",
      "Tue Apr 16 20:42:35 2024: Predicting ... \n",
      "elapsed: 0.104092\n",
      "/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/665bceba-78e2-46c5-9cec-653d08426c8f2.predictions.txt: /var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/665bceba-78e2-46c5-9cec-653d08426c8f2.model-10,#leaf=1000,#tree=124\n",
      "Tue Apr 16 20:42:35 2024: Done ... \n",
      "\n",
      "\"predict\": \n",
      "   model_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/c2e0616c-a13e-4efb-8c88-18f05b9ff68c3.model-10\n",
      "   test_x_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/c2e0616c-a13e-4efb-8c88-18f05b9ff68c3.test.data.x\n",
      "   prediction_fn=/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/c2e0616c-a13e-4efb-8c88-18f05b9ff68c3.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Tue Apr 16 20:42:36 2024: Reading test data ... \n",
      "Tue Apr 16 20:42:36 2024: Predicting ... \n",
      "elapsed: 0.106006\n",
      "/var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/c2e0616c-a13e-4efb-8c88-18f05b9ff68c3.predictions.txt: /var/folders/fy/4rjyh9dd1xndnwk2_jfvf7lw0000gn/T/rgf/c2e0616c-a13e-4efb-8c88-18f05b9ff68c3.model-10,#leaf=1000,#tree=115\n",
      "Tue Apr 16 20:42:36 2024: Done ... \n",
      "\n",
      "RGF_selected result: [0 0 0 ... 0 1 0]\n",
      "Misclassified samples: 5053\n",
      "Accuracy: 0.7037\n"
     ]
    }
   ],
   "source": [
    "# Create rgf classifier\n",
    "rgf = RGFClassifier(\n",
    "    max_leaf = 1000,\n",
    "    algorithm = \"RGF_Opt\",\n",
    "    test_interval = 100,\n",
    "    verbose = True)\n",
    "\n",
    "# Train\n",
    "rgf.fit(X_train_std, y_train_resampled)\n",
    "\n",
    "# Predict\n",
    "y_pred_rgf = rgf.predict(X_test_std)\n",
    "\n",
    "# Evaluation\n",
    "print('RGF_selected result:', y_pred_rgf)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_rgf).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_rgf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN result: [0 0 1 ... 0 0 0]\n",
      "Misclassified samples: 5563\n",
      "Accuracy: 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jack/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Multi-layer Perceptron classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), \n",
    "                    activation='relu', \n",
    "                    solver='adam', \n",
    "                    alpha=0.0001, \n",
    "                    batch_size='auto', \n",
    "                    learning_rate='constant', \n",
    "                    learning_rate_init=0.001, \n",
    "                    max_iter=200)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train_std, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_nn = mlp.predict(X_test_std)\n",
    "\n",
    "# Evaluation\n",
    "print('NN result:', y_pred_nn)\n",
    "print('Misclassified samples: %d' %(y_test != y_pred_nn).sum())\n",
    "print('Accuracy: %.4f' %accuracy_score(y_test, y_pred_nn)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict test.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_y_pred = rfc_filtered.predict(df_test_selected)\n",
    "fin_y_pred\n",
    "fin_df = pd.DataFrame({'label': fin_y_pred})\n",
    "fin_df.to_csv('rfc_output_0416.csv', index = True, index_label = 'Id')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1d69b23e567d7d0065b0ee7ea90b1ff2a48e881153cedf1c7b2d00f616e254e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
